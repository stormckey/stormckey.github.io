---
nostatistics: true
---
# Research

!!! info "è™½ç„¶æ˜¯ç§‘ç ”èœğŸ¶ä½†è¿˜æ˜¯æŠŠä¸€äº›ç¬”è®°æ”¾åœ¨è¿™é‡Œå¥½äº† QaQ"

!!! abstract "Research list"
    - [x] diffusion
    - [x] Unet
    - [x] batch nomarlization
    - [x] basic pytorch
    - [x] [:octicons-link-16:Stochastic Gradient Descent with momentum](https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d)
    - [x] [:octicons-link-16:KL æ•£åº¦](https://www.bilibili.com/video/BV1JY411q72n/?spm_id_from=333.337.search-card.all.click&vd_source=3bf0a9181b6c28910c810d7e49b5e64c)
    - [x] é‡å‚æ•°
    - [x] [:octicons-link-16:VAE](https://www.gwylab.com/note-vae.html) [:octicons-link-16:è¿˜æœ‰ä¸€ä¸ªå¾ˆä¼˜ç§€çš„è§£ç­”](https://zhuanlan.zhihu.com/p/348498294)

Useful pages:

- [:octicons-link-16:Reverse-mode automatic differentiation from scratch, in Python](https://sidsite.com/posts/autodiff/)
- [:octicons-link-16:Example implementation of reverse-mode autodiff](https://colab.research.google.com/drive/1VpeE6UvEPRz9HmsHh1KS0XxXjYu533EC#scrollTo=erjC686T4S4c)


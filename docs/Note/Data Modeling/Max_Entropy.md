# 最大熵模型

!!! info "思想"
    有时候我们已有的数据并不足以我们唯一确定一个分布，这个时候对于所有候选的分布中，我们认为熵最大的那个分布是最好的.换言之，在满足约束的情况下，我们尽可能采取等可能分布。

## 模型描述

对于数据集$\{(x_i,y_i)\}$,统计经验分布（也就是频率）

\begin{aligned}
    &\tilde{P}(X=x,Y=y) = \frac{v(X = x, Y = y)}{N} \\
    &\tilde{P}(X=x) = \frac{v(X = x)}{N} \\
\end{aligned}

我们引入特征函数$f(x,y) \ in {0,1}$,我们可以置顶某种条件，满足条件的$(x,y)$对应的特征函数值为 1,否则为 0.比如我们可以定义$f(x,y) = 1$当且仅当$x$和$y$相等，否则为 0.定义了一个特征函数，我们就可以定义在特征函数上的期望：

$$
    E_{\tilde{P}}(f) = \sum_{x,y}\tilde{P}(x,y)f(x,y)
$$

简单来说，这就是对某些$(x,y)$上的频数求和，在上例中，就是对 xy 相等的那些项的频数求和

假设我们学习到了一个条件分布$P(Y|X)$,那么用我们学到的条件分布与 X 的经验分布算出来的期望是：

$$
    E_{P}(f) = \sum_{x,y}P(y|x)\tilde{P}(x)f(x,y)
$$

我们希望我们学到的条件呢分布尽可能符合实际，也就是$P(y|x)\tilde{P}(x)$在特征函数的意义上尽可能贴近$\tilde{P}(x,y)$,也就是说

$$
    E_{P}(f) = E_{\tilde{P}}(f)
$$

如果我们用上面例子中的特征函数，这里的意思就是我们学习到的分布中，xy 相等的频数等于实际观测到的 xy 相等的频数。

这里就是我们在思想中提到的约束，满足这样约束的模型并不唯一，我们计算各个模型的条件熵：

$$
    H(P) = -\sum_{x,y}\tilde{P}(x)P(y|x)\log P(y|x)
$$

我们希望条件熵最大，条件熵越大的分布越好，这是一个优化问题。

## 模型求解

写出形式化表达式：

\begin{aligned}
    \underset{P \in C}{\operatorname{min}} &-H(P) = \sum_{x,y}\tilde{P}(x)P(y|x)\log P(y|x) \\
    s.t. &\sum_{y}P(y|x) = 1 \\
    & E_{P}(f_i) = E_{\tilde{P}}(f_i) \\
\end{aligned}

注意到我们可以用多个特征函数来进行约束

为了解觉优化问题，我们用以下三步

- 写出对偶问题，拉格朗日函数$L(P,w)$为：
    $$
        \undreset{P \in C}{\operatorname{min}} \underset{w}{\operatorname{max}} L(P,w) = \sum_{x,y}\tilde{P}(x)P(y|x)\log P(y|x) + \sum_{i=1}^{n}w_i(\sum_{x,y}\tilde{P}(x)P(y|x)f_i(x,y) - E_{\tilde{P}}(f_i))
    $$
- 极小化：在$L(P,w)$中对 P 求偏导以进行最小化
- 极大化：同样求导或者使用其他最优化算法（梯度下降法，牛顿法，拟牛顿法）

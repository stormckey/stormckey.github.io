---
comments: true
---

# 逻辑斯谛回归

### 逻辑斯谛分布

首先直接给出逻辑斯蒂分布，一个随机变量$X$满足$Logistic(\mu,\gamma)$分布的分布函数：

$$
F(x)=\frac{1}{1+e^{-(x-\mu)/\gamma}}
$$

其中$\mu$为位置参数，$\gamma$为形状参数。该分布函数的图像为 S 型曲线，$\mu$为函数的对称中心，$\gamma$控制函数的陡峭程度，值越大，函数越陡峭。

![](images/Logistic_Regression/2023-11-25-23-39-04.png#pic)

## 二项逻辑斯谛回归模型

给定数据集$D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}$，其中$x_i \in \mathbb{R}$，$y_i \in \{0,1\}$，我们的目标是学习到一个线性模型来进行分类，在感知机中，我们用一个指示函数来将函数值的符号映射到不同的分类。

对于逻辑斯蒂回归来说，我们想要得到的是某个 x 下属于 0，或者 1 的概率，因为分布函数也是连续的，所以我们可以试图用线性的模型去拟合，我们先作如下的转化：

- 概率的取值范围是$P \in [0,1]$
- 如果我们使用几率$\frac{p}{1-p}$，那么我们的取值范围就是$(0,\infty)$
- 再加一个对数，我们就得到对数几率$logit(p)=ln\frac{p}{1-p}$，取值范围是$(-\infty,\infty)$

这样对数几率的取值范围就和线性函数的一样了，我们就可以试着用线性函数去进行拟合（如果某个分布的对数函数相关系数很高，自然可以拟合到比较好的效果，但如果一个分布的对数几率几乎不成线性，那么线性函数的拟合效果就会比较差。所以我们用逻辑斯蒂回归拟合的分布最好有类似逻辑斯蒂分布的分布函数）。

我们令

$$
    \ln(\frac{P(Y=1|x)}{1-P(Y=1|x)}) = w\cdot x + b
$$

那么就可以得到：

$$
P(Y=1|x)=\frac{exp(w\cdot x+b)}{1+exp(w\cdot x+b)}
$$

$$
P(Y=0|x)=\frac{1}{1+exp(w\cdot x+b)}
$$

这就是逻辑斯蒂回归，现在问题是我们有的是一对数据点而不是 x 和对应的概率，我们该如何进行拟合？

## 极大似然估计

我们定义如下的似然函数

$$
    L(w,b)=\prod_{i=1}^{m}P(Y=y_i|x_i)=\prod_{i=1}^{m}(\frac{exp(w\cdot x_i+b)}{1+exp(w\cdot x_i+b)})^{y_i}(\frac{1}{1+exp(w\cdot x_i+b)})^{1-y_i}
$$

为了方便求解，我们可以极大化对数似然函数，这也等效于极大化似然函数，因为对数函数是单调递增的。

\begin{aligned}
    &\ln L(w,b) = \sum_{i=1}^{m}y_i(w\cdot x_i+b)-\ln(1+exp(w\cdot x_i+b)) \\
\end{aligned}

那么极大似然估计就要求我们找到使对数似然函数最大的参数

$$
    \underset{w,b}{\operatorname{arg max}}  \ln L(w,b)
$$



在这个具体的求解过程需要用梯度下降法或者牛顿法，注意到因为逻辑斯蒂函数是凸函数，所以我们可以保证求解的结果是全局最优解。

## 多项逻辑斯谛回归模型

类似的，多项逻辑斯蒂分布的分布函数如下：

\begin{aligned}
    &P(Y=1|x)=\frac{exp(w_1\cdot x+b_1)}{1+\sum_{i=1}^{k-1} e^{w_i \cdot x + b_i}} \\
    &P(Y=2|x)=\frac{exp(w_2\cdot x+b_2)}{1+\sum_{i=1}^{k-1} e^{w_i \cdot x + b_i}} \\
    &... \\
    &P(Y=k|x)=\frac{1}{1+\sum_{i=1}^{k-1} e^{w_i \cdot x + b_i}} \\
\end{aligned}
